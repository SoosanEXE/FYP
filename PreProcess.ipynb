{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "     NSL-KDD                         |     UNSW-NB15                 \n",
      "---------------------------------------------------------------------\n",
      "     Dataset Loaded NSL-KDD          |    Dataset Loaded UNSW-NB15   \n",
      "---------------------------------------------------------------------\n",
      "     Dataset Scaling is finished     |    Dataset Scaling is finished\n",
      "---------------------------------------------------------------------\n",
      "     Performing feature selection    |    Performing feature selection\n",
      "---------------------------------------------------------------------\n",
      "     Performing One Hot encoding     |    Performing One Hot encoding\n",
      "---------------------------------------------------------------------\n",
      "     Dataset preprocessed!           |    Dataset preprocessed!       \n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from DataSets import constants as paths\n",
    "from DataPreprocess import constants\n",
    "from DataPreprocess.BinaryClassMapping import BinMap, BinMap1\n",
    "from DataPreprocess.Scaling import Scaling\n",
    "from DataPreprocess.Encoding import Encoding\n",
    "from DataPreprocess.FeatureSelection import FeatureSelection\n",
    "from AnomalyClassifier.AnomalyClassifier import AnomalyClassifier_nsl, AnomalyClassifier_unsw\n",
    "from EvalMetrics.EvalMetrics import EvalMetrics\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##########################\n",
    "\n",
    "#read datasets\n",
    "kdd_train = pd.read_csv(\"/home/soosan/fyp/FYP/DataSets/KDDTrain+.txt\", header=None, names=constants.COL_NAMES)\n",
    "kdd_test = pd.read_csv(\"/home/soosan/fyp/FYP/DataSets/KDDTest+.txt\", header=None, names=constants.COL_NAMES)\n",
    "\n",
    "unsw_train = pd.read_csv(\"/home/soosan/fyp/FYP/DataSets/UNSW_NB15_training-set.csv\")\n",
    "unsw_test = pd.read_csv(\"/home/soosan/fyp/FYP/DataSets/UNSW_NB15_testing-set.csv\")\n",
    "\n",
    "#make them as one\n",
    "df = pd.concat([kdd_train, kdd_test])\n",
    "df1 = pd.concat([unsw_train, unsw_test])\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"     NSL-KDD                         |     UNSW-NB15                 \")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"     Dataset Loaded NSL-KDD          |    Dataset Loaded UNSW-NB15   \")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "#map attack type to 0 or 1\n",
    "df = BinMap(df, constants.NSL_TARGET)\n",
    "df1 = BinMap(df1, constants.UNSW_TARGET)\n",
    "#scale numerical columns\n",
    "df = Scaling.scaling(df, df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "df1 = Scaling.scaling(df1, df1.select_dtypes(include=['float64', 'int64']).columns)\n",
    "\n",
    "print(\"     Dataset Scaling is finished     |    Dataset Scaling is finished\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "#for feature selection before make a copy\n",
    "\n",
    "print(\"     Performing feature selection    |    Performing feature selection\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy1 = df1.copy()\n",
    "#label encode categorical values\n",
    "df_copy = Encoding.Labencoding(df_copy)\n",
    "df_copy1 = Encoding.Labencoding(df_copy1)\n",
    "#Feature Selection\n",
    "X = df_copy.drop('attack_class', axis=1)\n",
    "y = df_copy['attack_class']\n",
    "\n",
    "X1 = df_copy1.drop('attack_cat', axis=1)\n",
    "y1 = df_copy1['attack_cat']\n",
    "#n = [10, 13, 15, 17, 21]\n",
    "\n",
    "#for i in n:\n",
    "new_fs = FeatureSelection.select_features(X, y, 'attack_class', 15)\n",
    "#print(\"Selected features: \")\n",
    "#print(new_fs)\n",
    "df_new = df[new_fs]\n",
    "\n",
    "new_fs1 = FeatureSelection.select_features(X1, y1, 'attack_cat', 15)\n",
    "#print(\"Selected features: \")\n",
    "#print(new_fs1)\n",
    "df_new1 = df1[new_fs1]\n",
    "print(\"     Performing One Hot encoding     |    Performing One Hot encoding\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "df_new = Encoding.OHencoding(df)\n",
    "df_new1 = Encoding.OHencoding(df1)\n",
    "df_new.to_parquet(\"KDDpreprocessed.parquet\")\n",
    "df_new1.to_parquet(\"UNSWpreprocessed.parquet\")\n",
    "print(\"     Dataset preprocessed!           |    Dataset preprocessed!       \")\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8f14f5a7c49a331ac7a55934b43ce13bd28be1333db14e2d71768ad3378996c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
